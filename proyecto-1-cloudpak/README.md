# ğŸš€ Pipeline ETL con IBM DataStage y Snowflake

ğŸ“‹ DescripciÃ³n del Proyecto
Pipeline ETL completo desarrollado en **IBM Cloud Pak for Data** usando **DataStage** para orquestaciÃ³n visual. ExtracciÃ³n, transformaciÃ³n y carga de datos entre diferentes esquemas de Snowflake.

ğŸ—ï¸ Arquitectura

**Flujo de Datos:**
1. **Origen**: Snowflake (tablas raw/operacionales)
2. **ETL**: IBM DataStage en Cloud Pak for Data
   - ExtracciÃ³n via Snowflake connector
   - Transformaciones con stages visuales
   - Validaciones de calidad
3. **Destino**: Snowflake (tablas analÃ­ticas/curated)


ğŸ› ï¸ TecnologÃ­as Utilizadas
    IBM Cloud Pak for Data - Plataforma unificada
    DataStage - OrquestraciÃ³n ETL visual
    Snowflake - Data Warehouse (origen y destino)
    SQL - Transformaciones y consultas


ğŸ“Š Flujo del Pipeline
    ExtracciÃ³n: Consulta a tablas origen en Snowflake
    TransformaciÃ³n:
    Limpieza y estandarizaciÃ³n de datos
    Joins entre mÃºltiples fuentes
    CÃ¡lculo de mÃ©tricas de negocio
    Carga: InserciÃ³n en tablas destino optimizadas


ğŸ¯ Componentes de DataStage Utilizados
    Sequential File Stage - Manejo de datos planos
    Transformer Stage - LÃ³gica de transformaciÃ³n
    Snowflake Connector - ConexiÃ³n bidireccional
    Quality Stage - ValidaciÃ³n de datos


ğŸ“ˆ Resultados Obtenidos

âœ… Pipeline ejecutÃ¡ndose en producciÃ³n

âœ… Procesamiento de X registros diarios

âœ… ReducciÃ³n de X% en tiempo de transformaciÃ³n

âœ… Mejora en calidad de datos del X%

